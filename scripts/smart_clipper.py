#!/usr/bin/env python3
"""
æ™ºèƒ½åˆ‡ç‰‡å†³ç­–å¼•æ“
ç»“åˆå¼¹å¹•å¯†åº¦å’Œå­—å¹•è¯­ä¹‰åˆ†æï¼Œç”Ÿæˆæœ€ä¼˜åˆ‡ç‰‡æ–¹æ¡ˆ
"""

import json
import os
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass, asdict


@dataclass
class ClipRecommendation:
    """åˆ‡ç‰‡æ¨è"""

    start: float
    end: float
    duration: float
    title: str
    keywords: List[str]
    score: int  # 0-100
    score_breakdown: Dict[str, int]  # å„ç»´åº¦å¾—åˆ†
    reason: str  # æ¨èç†ç”±


class SmartClipper:
    """æ™ºèƒ½åˆ‡ç‰‡å™¨"""

    # è¯„åˆ†æƒé‡
    WEIGHTS = {
        "danmaku_density": 0.30,  # å¼¹å¹•å¯†åº¦ 30%
        "semantic_quality": 0.40,  # è¯­ä¹‰è´¨é‡ 40%
        "template_match": 0.20,  # æ¨¡æ¿åŒ¹é… 20%
        "duration_fit": 0.10,  # æ—¶é•¿åˆé€‚ 10%
    }

    def __init__(self, template: Optional[Dict] = None):
        """
        Args:
            template: ä¸»æ’­æ¨¡æ¿é…ç½®
        """
        self.template = template or {}
        self.clip_config = template.get("clip_config", {}) if template else {}

    def load_analysis(
        self, danmaku_result_path: str, semantic_result_path: str
    ) -> Tuple[Dict, Dict]:
        """åŠ è½½åˆ†æç»“æœ"""
        with open(danmaku_result_path, "r", encoding="utf-8") as f:
            danmaku_result = json.load(f)

        with open(semantic_result_path, "r", encoding="utf-8") as f:
            semantic_result = json.load(f)

        return danmaku_result, semantic_result

    def score_danmaku_density(self, moment: Dict) -> int:
        """
        è¯„åˆ†å¼¹å¹•å¯†åº¦ (0-100)
        åŸºäºå¯†åº¦ç›¸å¯¹äºå¹³å‡å€¼çš„æ¯”ä¾‹
        """
        density = moment.get("density", 0)

        # ç®€å•è¯„åˆ†ï¼šå¯†åº¦è¶Šé«˜åˆ†è¶Šé«˜
        if density >= 150:
            score = 100
        elif density >= 100:
            score = 80
        elif density >= 80:
            score = 60
        elif density >= 50:
            score = 40
        else:
            score = 20

        return score

    def score_semantic_quality(self, highlight: Dict) -> int:
        """
        è¯„è¯è¯­ä¹‰è´¨é‡ (0-100)
        åŸºäºå…´å¥‹åº¦å’Œå†…å®¹è´¨é‡
        """
        excitement = highlight.get("excitement_score", 1)

        # å…´å¥‹åº¦ 1-5 æ˜ å°„åˆ° 20-100
        score = excitement * 20

        # å¦‚æœæœ‰å…³é”®è¯­å½•ï¼Œé¢å¤–åŠ åˆ†
        if highlight.get("key_quotes"):
            score = min(100, score + 10)

        return score

    def score_template_match(self, moment: Dict, highlight: Dict) -> int:
        """
        è¯„åˆ†æ¨¡æ¿åŒ¹é…åº¦ (0-100)
        æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸»æ’­çš„ç»å…¸æ¢—
        """
        score = 50  # åŸºç¡€åˆ†

        if not self.template:
            return score

        memes = self.template.get("memes", [])
        keywords = moment.get("keywords", []) + highlight.get("keywords", [])

        # æ£€æŸ¥å…³é”®è¯æ˜¯å¦åŒ…å«æ¢—
        text = " ".join(keywords).lower()
        matched_memes = [meme for meme in memes if meme.lower() in text]

        # æ¯åŒ¹é…ä¸€ä¸ªæ¢—åŠ 10åˆ†
        score += len(matched_memes) * 10

        return min(100, score)

    def score_duration_fit(self, duration: float) -> int:
        """
        è¯„åˆ†æ—¶é•¿åˆé€‚åº¦ (0-100)
        åŸºäºæ¨¡æ¿æ¨èæ—¶é•¿
        """
        if not self.clip_config:
            # é»˜è®¤ 1-3 åˆ†é’Ÿåˆé€‚
            if 60 <= duration <= 180:
                return 100
            elif 30 <= duration < 60 or 180 < duration <= 300:
                return 70
            else:
                return 40

        min_duration = self.clip_config.get("min_duration", 60)
        max_duration = self.clip_config.get("max_duration", 300)

        if min_duration <= duration <= max_duration:
            return 100
        elif duration < min_duration:
            # å¤ªçŸ­
            return max(0, 100 - (min_duration - duration) * 2)
        else:
            # å¤ªé•¿
            return max(0, 100 - (duration - max_duration) * 0.5)

    def generate_title(self, keywords: List[str], highlight: Dict) -> str:
        """ç”Ÿæˆåˆ‡ç‰‡æ ‡é¢˜"""
        streamer = self.template.get("name", "ä¸»æ’­")

        # é€‰æ‹©æœ€é‡è¦çš„å…³é”®è¯
        main_keyword = keywords[0] if keywords else "ç²¾å½©æ—¶åˆ»"

        # å¦‚æœæœ‰å…³é”®è¯­å½•ï¼Œä¼˜å…ˆä½¿ç”¨
        if highlight.get("key_quotes"):
            quote = highlight["key_quotes"][0]
            if len(quote) <= 20:
                title = f"[{streamer}] {quote}"
            else:
                title = f"[{streamer}]{main_keyword} | é«˜èƒ½ååœºé¢"
        else:
            title = f"[{streamer}]{main_keyword} | ç²¾å½©ç‰‡æ®µ"

        # é™åˆ¶é•¿åº¦
        if len(title) > 80:
            title = title[:77] + "..."

        return title

    def merge_moments(self, danmaku_result: Dict, semantic_result: Dict) -> List[Dict]:
        """
        åˆå¹¶å¼¹å¹•å’Œè¯­ä¹‰åˆ†æçš„æ—¶åˆ»
        æ‰¾å‡ºä¸¤è€…éƒ½è®¤ä¸ºæ˜¯ç²¾å½©çš„æ—¶æ®µ
        """
        merged = []

        # è·å–å¼¹å¹•é«˜å³°æ—¶åˆ»
        danmaku_peaks = danmaku_result.get("peak_moments", [])

        # è·å–è¯­ä¹‰ç²¾å½©ç‰‡æ®µ
        semantic_highlights = semantic_result.get("highlights", [])

        # 1. ç›´æ¥åŒ¹é…é‡å æ—¶æ®µ
        for dm_peak in danmaku_peaks:
            dm_start, dm_end = dm_peak["start"], dm_peak["end"]

            for hl in semantic_highlights:
                hl_start, hl_end = hl["start"], hl["end"]

                # æ£€æŸ¥æ—¶é—´é‡å 
                overlap = max(0, min(dm_end, hl_end) - max(dm_start, hl_start))

                if overlap > 10:  # è‡³å°‘é‡å 10ç§’
                    # åˆå¹¶æ—¶æ®µ
                    merged_start = min(dm_start, hl_start)
                    merged_end = max(dm_end, hl_end)

                    # é™åˆ¶æœ€å¤§æ—¶é•¿ï¼ˆ3åˆ†é’Ÿï¼‰
                    if merged_end - merged_start > 180:
                        merged_end = merged_start + 180

                    merged.append(
                        {
                            "start": merged_start,
                            "end": merged_end,
                            "danmaku": dm_peak,
                            "semantic": hl,
                            "overlap": overlap,
                        }
                    )

        # 2. å¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„é‡å ï¼Œå•ç‹¬æ·»åŠ é«˜åˆ†é¡¹
        if len(merged) < 5:
            # æ·»åŠ å¼¹å¹•é«˜å³°
            for dm_peak in danmaku_peaks[:5]:
                if not any(m["danmaku"] == dm_peak for m in merged):
                    merged.append(
                        {
                            "start": dm_peak["start"],
                            "end": dm_peak["end"],
                            "danmaku": dm_peak,
                            "semantic": None,
                            "overlap": 0,
                        }
                    )

            # æ·»åŠ è¯­ä¹‰äº®ç‚¹
            for hl in semantic_highlights[:5]:
                if not any(m["semantic"] == hl for m in merged):
                    merged.append(
                        {
                            "start": hl["start"],
                            "end": hl["end"],
                            "danmaku": None,
                            "semantic": hl,
                            "overlap": 0,
                        }
                    )

        # å»é‡å¹¶æ’åº
        seen = set()
        unique_merged = []
        for m in merged:
            key = (int(m["start"]), int(m["end"]))
            if key not in seen:
                seen.add(key)
                unique_merged.append(m)

        unique_merged.sort(key=lambda x: x["start"])

        return unique_merged

    def generate_recommendations(
        self, danmaku_result_path: str, semantic_result_path: str, top_n: int = 10
    ) -> List[ClipRecommendation]:
        """
        ç”Ÿæˆåˆ‡ç‰‡æ¨è

        Returns:
            List[ClipRecommendation]: æ¨èåˆ‡ç‰‡åˆ—è¡¨
        """
        print("ğŸ§  æ™ºèƒ½åˆ‡ç‰‡å†³ç­–ä¸­...")

        # åŠ è½½åˆ†æç»“æœ
        danmaku_result, semantic_result = self.load_analysis(
            danmaku_result_path, semantic_result_path
        )

        # åˆå¹¶æ—¶åˆ»
        merged = self.merge_moments(danmaku_result, semantic_result)
        print(f"   æ‰¾åˆ° {len(merged)} ä¸ªå€™é€‰æ—¶æ®µ")

        # è¯„åˆ†æ¯ä¸ªå€™é€‰
        recommendations = []

        for moment in merged:
            dm_data = moment.get("danmaku", {}) or {}
            hl_data = moment.get("semantic", {}) or {}

            duration = moment["end"] - moment["start"]

            # å„ç»´åº¦è¯„åˆ†
            dm_score = self.score_danmaku_density(dm_data)
            sem_score = self.score_semantic_quality(hl_data)
            template_score = self.score_template_match(dm_data, hl_data)
            duration_score = self.score_duration_fit(duration)

            # åŠ æƒæ€»åˆ†
            total_score = int(
                dm_score * self.WEIGHTS["danmaku_density"]
                + sem_score * self.WEIGHTS["semantic_quality"]
                + template_score * self.WEIGHTS["template_match"]
                + duration_score * self.WEIGHTS["duration_fit"]
            )

            # æ”¶é›†å…³é”®è¯
            keywords = []
            if dm_data.get("keywords"):
                keywords.extend(dm_data["keywords"])
            if hl_data.get("keywords"):
                keywords.extend(hl_data["keywords"])
            keywords = list(dict.fromkeys(keywords))[:5]  # å»é‡å¹¶é™åˆ¶

            # ç”Ÿæˆæ¨èç†ç”±
            reasons = []
            if dm_data.get("density", 0) > 80:
                reasons.append("å¼¹å¹•å¯†é›†")
            if hl_data.get("excitement_score", 0) >= 4:
                reasons.append("æƒ…ç»ªé«˜æ¶¨")
            if template_score > 70:
                reasons.append("åŒ…å«ç»å…¸æ¢—")

            reason = " + ".join(reasons) if reasons else "ç²¾å½©ç‰‡æ®µ"

            # ç”Ÿæˆæ ‡é¢˜
            title = self.generate_title(keywords, hl_data)

            recommendation = ClipRecommendation(
                start=moment["start"],
                end=moment["end"],
                duration=duration,
                title=title,
                keywords=keywords,
                score=total_score,
                score_breakdown={
                    "danmaku": dm_score,
                    "semantic": sem_score,
                    "template": template_score,
                    "duration": duration_score,
                },
                reason=reason,
            )

            recommendations.append(recommendation)

        # æŒ‰æ€»åˆ†æ’åº
        recommendations.sort(key=lambda x: x.score, reverse=True)

        # å»é‡ï¼ˆæ—¶é—´è¿‡äºæ¥è¿‘çš„åªä¿ç•™æœ€é«˜åˆ†ï¼‰
        filtered = []
        for rec in recommendations:
            # æ£€æŸ¥æ˜¯å¦ä¸å·²ä¿ç•™çš„æ—¶æ®µé‡å å¤ªå¤š
            overlap = False
            for kept in filtered:
                overlap_start = max(rec.start, kept.start)
                overlap_end = min(rec.end, kept.end)
                if overlap_end - overlap_start > 30:  # é‡å è¶…è¿‡30ç§’
                    overlap = True
                    break

            if not overlap:
                filtered.append(rec)

        return filtered[:top_n]

    def save_recommendations(
        self, recommendations: List[ClipRecommendation], output_path: str
    ):
        """ä¿å­˜æ¨èç»“æœ"""
        result = {
            "total_recommendations": len(recommendations),
            "clips": [asdict(rec) for rec in recommendations],
        }

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        print(f"\nâœ… ç”Ÿæˆ {len(recommendations)} ä¸ªåˆ‡ç‰‡æ¨è")
        print(f"   ç»“æœå·²ä¿å­˜: {output_path}")

    def display_recommendations(self, recommendations: List[ClipRecommendation]):
        """å±•ç¤ºæ¨èç»“æœ"""
        print("\n" + "=" * 60)
        print("ğŸ¬ æ™ºèƒ½åˆ‡ç‰‡æ¨è")
        print("=" * 60)

        for i, rec in enumerate(recommendations[:10], 1):
            start_min = int(rec.start // 60)
            start_sec = int(rec.start % 60)
            end_min = int(rec.end // 60)
            end_sec = int(rec.end % 60)

            print(f"\nåˆ‡ç‰‡ {i}/{len(recommendations)} (è¯„åˆ†: {rec.score}/100)")
            print(
                f"   æ—¶é—´: {start_min:02d}:{start_sec:02d} - {end_min:02d}:{end_sec:02d} ({int(rec.duration)}ç§’)"
            )
            print(f"   æ ‡é¢˜: {rec.title}")
            print(f"   å…³é”®è¯: {', '.join(rec.keywords)}")
            print(f"   æ¨èç†ç”±: {rec.reason}")

            # æ˜¾ç¤ºå¾—åˆ†è¯¦æƒ…
            breakdown = rec.score_breakdown
            print(
                f"   å¾—åˆ†è¯¦æƒ…: å¼¹å¹•{breakdown['danmaku']} + è¯­ä¹‰{breakdown['semantic']} + "
                f"æ¨¡æ¿{breakdown['template']} + æ—¶é•¿{breakdown['duration']}"
            )


def main():
    import argparse

    parser = argparse.ArgumentParser(description="æ™ºèƒ½åˆ‡ç‰‡å†³ç­–")
    parser.add_argument("--danmaku", "-d", required=True, help="å¼¹å¹•åˆ†æç»“æœ JSON")
    parser.add_argument("--semantic", "-s", required=True, help="è¯­ä¹‰åˆ†æç»“æœ JSON")
    parser.add_argument("--template", "-t", help="ä¸»æ’­æ¨¡æ¿ JSON")
    parser.add_argument("--output", "-o", help="è¾“å‡ºè·¯å¾„")
    parser.add_argument("--top-n", "-n", type=int, default=10, help="æ¨èæ•°é‡")

    args = parser.parse_args()

    # åŠ è½½æ¨¡æ¿
    template = None
    if args.template and os.path.exists(args.template):
        with open(args.template, "r", encoding="utf-8") as f:
            template = json.load(f)

    # åˆ›å»ºæ™ºèƒ½åˆ‡ç‰‡å™¨
    clipper = SmartClipper(template)

    # ç”Ÿæˆæ¨è
    recommendations = clipper.generate_recommendations(
        args.danmaku, args.semantic, top_n=args.top_n
    )

    # å±•ç¤ºç»“æœ
    clipper.display_recommendations(recommendations)

    # ä¿å­˜ç»“æœ
    if args.output:
        clipper.save_recommendations(recommendations, args.output)
    else:
        output_path = Path(args.danmaku).parent / "clip_recommendations.json"
        clipper.save_recommendations(recommendations, str(output_path))


if __name__ == "__main__":
    main()
