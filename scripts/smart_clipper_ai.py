#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI-powered æ™ºèƒ½åˆ‡ç‰‡è„šæœ¬
æ•´åˆå­—å¹•åˆ†æã€ç²¾å½©ç‰‡æ®µè¯†åˆ«ã€æ ‡é¢˜ç”Ÿæˆå…¨æµç¨‹
"""

import json
import argparse
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from analyze_subtitles_ai import SubtitleAnalyzerAI
from generate_title_ai import AITitleGenerator


class SmartClipperAI:
    """
    AI-powered æ™ºèƒ½åˆ‡ç‰‡å™¨
    
    å®Œæ•´å·¥ä½œæµï¼š
    1. è§£æå­—å¹•æ–‡ä»¶
    2. AI åˆ†æç²¾å½©ç‰‡æ®µ
    3. AI ç”Ÿæˆæ ‡é¢˜
    4. è¾“å‡ºåˆ‡ç‰‡æ–¹æ¡ˆ
    """

    def __init__(self, streamer_name: str = "Unknown", template_path: str = None):
        """
        åˆå§‹åŒ–æ™ºèƒ½åˆ‡ç‰‡å™¨
        
        Args:
            streamer_name: ä¸»æ’­åç§°
            template_path: ä¸»æ’­æ¨¡æ¿æ–‡ä»¶è·¯å¾„
        """
        self.streamer_name = streamer_name
        self.streamer_template = self._load_template(template_path)
        
        # åˆå§‹åŒ–å­æ¨¡å—
        self.analyzer = SubtitleAnalyzerAI(
            streamer_name=streamer_name,
            streamer_template=self.streamer_template
        )
        
        self.title_generator = AITitleGenerator(
            streamer_name=streamer_name,
            streamer_template=self.streamer_template
        )

    def _load_template(self, template_path: str = None) -> Dict:
        """åŠ è½½ä¸»æ’­æ¨¡æ¿"""
        if not template_path:
            # å°è¯•é»˜è®¤è·¯å¾„
            default_path = Path(__file__).parent.parent / "config" / "streamer_templates.yaml"
            if default_path.exists():
                template_path = str(default_path)
            else:
                return {}
        
        if not Path(template_path).exists():
            return {}
        
        import yaml
        try:
            with open(template_path, "r", encoding="utf-8") as f:
                data = yaml.safe_load(f)
                # å°è¯•è·å–ä¸»æ’­æ¨¡æ¿
                streamers = data.get("streamers", {})
                # å°è¯•ç²¾ç¡®åŒ¹é…
                key = self.streamer_name.lower().replace(" ", "_")
                return streamers.get(key, streamers.get(self.streamer_name, {}))
        except Exception:
            return {}

    def run_full_pipeline(
        self,
        subtitle_path: str,
        output_dir: str = None,
        num_highlights: int = 5,
        platform: str = "bilibili"
    ) -> Dict:
        """
        è¿è¡Œå®Œæ•´ AI åˆ‡ç‰‡æµç¨‹
        
        Args:
            subtitle_path: å­—å¹•æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            num_highlights: ç”Ÿæˆçš„ç²¾å½©ç‰‡æ®µæ•°é‡
            platform: ç›®æ ‡å¹³å°
        
        Returns:
            å®Œæ•´åˆ†æç»“æœ
        """
        subtitle_path = Path(subtitle_path)
        
        print(f"\n{'='*60}")
        print(f"ğŸ¤– AI æ™ºèƒ½åˆ‡ç‰‡æµç¨‹å¯åŠ¨")
        print(f"{'='*60}")
        print(f"   ä¸»æ’­: {self.streamer_name}")
        print(f"   å­—å¹•: {subtitle_path.name}")
        print(f"   å¹³å°: {platform}")
        print(f"   ç›®æ ‡: {num_highlights} ä¸ªç²¾å½©ç‰‡æ®µ")
        
        output_dir = Path(output_dir) if output_dir else subtitle_path.parent / "ai_analysis"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Step 1: AI å­—å¹•åˆ†æ
        print(f"\nğŸ“Š Step 1: AI å­—å¹•åˆ†æ")
        print("-" * 40)
        
        analysis_result = self.analyzer.analyze_with_ai(str(subtitle_path))
        
        if "error" in analysis_result:
            return {"error": analysis_result["error"]}
        
        # ä¿å­˜åˆ†ææç¤ºè¯
        prompt_file = output_dir / f"{subtitle_path.stem}_ai_prompt.txt"
        with open(prompt_file, "w", encoding="utf-8") as f:
            f.write(analysis_result["ai_prompt"])
        print(f"   ğŸ’¾ AI æç¤ºè¯å·²ä¿å­˜: {prompt_file}")
        
        # Step 2: ç­‰å¾… AI åˆ†æç»“æœ
        print(f"\nğŸ“ Step 2: AI åˆ†æç»“æœè¾“å…¥")
        print("-" * 40)
        print(f"   âš ï¸  è¯·å°† Step 1 ç”Ÿæˆçš„æç¤ºè¯å‘é€ç»™ AI")
        print(f"   ğŸ“„ AI è¿”å›åˆ†æç»“æœåï¼Œä¿å­˜åˆ°æ–‡ä»¶")
        print(f"\n   ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç»§ç»­ï¼š")
        print(f"   python {Path(__file__).name} --subtitle {subtitle_path}")
        print(f"                 --ai-result <ai_output_json>")
        print(f"                 --output {output_dir}")
        
        # ç”Ÿæˆç»§ç»­å‘½ä»¤ç¤ºä¾‹
        continue_script = output_dir / "continue_pipeline.sh"
        with open(continue_script, "w", encoding="utf-8") as f:
            f.write(f'''#!/bin/bash
# ç»§ç»­ AI åˆ‡ç‰‡æµç¨‹
# 1. å°† AI è¿”å›çš„åˆ†æç»“æœä¿å­˜ä¸º ai_result.json
# 2. è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

python "{Path(__file__).name}" \\
    --subtitle "{subtitle_path}" \\
    --ai-result ./ai_result.json \\
    --output ./
''')
        print(f"   ğŸ“œ ç»§ç»­è„šæœ¬å·²ç”Ÿæˆ: {continue_script}")
        
        return {
            "step": "analysis_complete",
            "subtitle_file": str(subtitle_path),
            "ai_prompt_file": str(prompt_file),
            "output_dir": str(output_dir),
            "next_step": "è¯·å°† AI è¿”å›çš„åˆ†æç»“æœä¿å­˜ä¸º JSON æ–‡ä»¶ï¼Œç„¶åè¿è¡Œç»§ç»­å‘½ä»¤"
        }

    def continue_pipeline(
        self,
        subtitle_path: str,
        ai_result_path: str = None,
        ai_result_json: str = None,
        output_dir: str = None,
        num_highlights: int = 5,
        platform: str = "bilibili"
    ) -> Dict:
        """
        ç»§ç»­åˆ‡ç‰‡æµç¨‹ï¼ˆStep 2ï¼‰
        
        Args:
            subtitle_path: å­—å¹•æ–‡ä»¶è·¯å¾„
            ai_result_path: AI åˆ†æç»“æœæ–‡ä»¶è·¯å¾„
            ai_result_json: AI åˆ†æç»“æœ JSON å­—ç¬¦ä¸²
            output_dir: è¾“å‡ºç›®å½•
            num_highlights: ç”Ÿæˆçš„ç²¾å½©ç‰‡æ®µæ•°é‡
            platform: ç›®æ ‡å¹³å°
        """
        subtitle_path = Path(subtitle_path)
        
        # Step 3: è§£æ AI åˆ†æç»“æœ
        print(f"\nğŸ“Š Step 3: è§£æ AI åˆ†æç»“æœ")
        print("-" * 40)
        
        if ai_result_path and Path(ai_result_path).exists():
            with open(ai_result_path, "r", encoding="utf-8") as f:
                ai_output = f.read()
        elif ai_result_json:
            ai_output = ai_result_json
        else:
            # å°è¯•ä» .ai_analysis ç›®å½•è¯»å–
            analysis_dir = subtitle_path.parent / "ai_analysis"
            ai_result_file = analysis_dir / "ai_result.json"
            if ai_result_file.exists():
                with open(ai_result_file, "r", encoding="utf-8") as f:
                    ai_output = f.read()
            else:
                return {"error": "æœªæ‰¾åˆ° AI åˆ†æç»“æœ"}
        
        # è§£æ AI è¿”å›çš„ç»“æœ
        highlights = []
        try:
            # å°è¯•æå– JSON
            import re
            json_match = re.search(r'```json\s*(.+?)\s*```', ai_output, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group(1))
            else:
                result = json.loads(ai_output)
            
            highlights = result.get("highlights", [])[:num_highlights]
            
        except json.JSONDecodeError:
            # æ‰‹åŠ¨è§£æï¼ˆå¦‚æœ AI è¿”å›çš„æ˜¯æ–‡æœ¬æè¿°ï¼‰
            print(f"   âš ï¸  AI è¿”å›æ ¼å¼ä¸æ˜¯æ ‡å‡† JSON")
            print(f"   ğŸ“„ è¿”å›å†…å®¹é¢„è§ˆ: {ai_output[:500]}...")
            
            # å°è¯•ä»æ–‡æœ¬ä¸­æå–ä¿¡æ¯
            highlights = self._parse_text_result(ai_output)
        
        if not highlights:
            return {"error": "æ— æ³•è§£æ AI åˆ†æç»“æœ"}
        
        print(f"   âœ… è§£æåˆ° {len(highlights)} ä¸ªç²¾å½©ç‰‡æ®µ")
        
        # Step 4: ç”Ÿæˆæ ‡é¢˜
        print(f"\nğŸ“ Step 4: AI æ ‡é¢˜ç”Ÿæˆ")
        print("-" * 40)
        
        output_dir = Path(output_dir) if output_dir else subtitle_path.parent / "ai_analysis"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        clips = []
        for i, highlight in enumerate(highlights, 1):
            print(f"\n   [{i}/{len(highlights)}] å¤„ç†ç‰‡æ®µ...")
            
            # ç¡®ä¿æ—¶é—´æ ¼å¼æ­£ç¡®
            if isinstance(highlight.get("start_seconds"), str):
                highlight["start_seconds"] = self._parse_time_to_seconds(highlight.get("start_time", "0:00"))
            if isinstance(highlight.get("end_seconds"), str):
                highlight["end_seconds"] = self._parse_time_to_seconds(highlight.get("end_time", "0:00"))
            
            # ç”Ÿæˆæ ‡é¢˜
            title_result = self.title_generator.generate_titles(
                highlight,
                platform=platform,
                use_ai=True
            )
            
            # è¾“å‡ºæ ‡é¢˜ç”Ÿæˆæç¤ºè¯
            title_prompt_file = output_dir / f"clip_{i}_title_prompt.txt"
            with open(title_prompt_file, "w", encoding="utf-8") as f:
                f.write(title_result.description)
            
            print(f"       ğŸ¯ æ¨èæ ‡é¢˜: {title_result.recommended or 'ï¼ˆè¯·æŸ¥çœ‹æç¤ºè¯æ–‡ä»¶ï¼‰'}")
            print(f"       ğŸ’¾ æ ‡é¢˜æç¤ºè¯: {title_prompt_file}")
            
            clips.append({
                "index": i,
                "highlight": highlight,
                "title_result": {
                    "titles": [t.__dict__ for t in title_result.titles] if title_result.titles else [],
                    "recommended": title_result.recommended,
                    "prompt_file": str(title_prompt_file)
                },
                "tags": title_result.tags,
                "description": title_result.description
            })
        
        # Step 5: ç”Ÿæˆåˆ‡ç‰‡æ–¹æ¡ˆ
        print(f"\nğŸ“‹ Step 5: ç”Ÿæˆåˆ‡ç‰‡æ–¹æ¡ˆ")
        print("-" * 40)
        
        # æ„å»ºæœ€ç»ˆæ–¹æ¡ˆ
        final_plan = {
            "streamer": self.streamer_name,
            "subtitle_file": str(subtitle_path),
            "generated_at": datetime.now().isoformat(),
            "platform": platform,
            "total_clips": len(clips),
            "clips": []
        }
        
        for clip in clips:
            hl = clip["highlight"]
            final_plan["clips"].append({
                "index": clip["index"],
                "time_range": f"{self._format_time(hl.get('start_seconds', 0))} - {self._format_time(hl.get('end_seconds', 0))}",
                "start_seconds": hl.get("start_seconds"),
                "end_seconds": hl.get("end_seconds"),
                "duration_seconds": hl.get("end_seconds", 0) - hl.get("start_seconds", 0),
                "highlight_title": hl.get("title', 'ç²¾å½©ç‰‡æ®µ"),
                "reason": hl.get("reason', ''),
                "score": hl.get("score', 0),
                "keywords": hl.get('keywords', []),
                "quote": hl.get('quote'),
                "generated_titles": clip["title_result"]["titles"],
                "recommended_title": clip["title_result"]["recommended"],
                "tags": clip["tags"],
                "description": clip["description"]
            })
        
        # ä¿å­˜æ–¹æ¡ˆ
        plan_file = output_dir / f"{subtitle_path.stem}_clip_plan.json"
        with open(plan_file, "w", encoding="utf-8") as f:
            json.dump(final_plan, f, ensure_ascii=False, indent=2)
        
        print(f"   âœ… åˆ‡ç‰‡æ–¹æ¡ˆå·²ä¿å­˜: {plan_file}")
        
        # æ‰“å°æ‘˜è¦
        print(f"\n{'='*60}")
        print(f"ğŸ¬ AI æ™ºèƒ½åˆ‡ç‰‡å®Œæˆ!")
        print(f"{'='*60}")
        print(f"\nğŸ“Š ç”Ÿæˆ {final_plan['total_clips']} ä¸ªåˆ‡ç‰‡æ–¹æ¡ˆ:")
        
        for clip in final_plan["clips"]:
            print(f"\n   [{clip['index']}] {clip['time_range']}")
            print(f"       â­ æ¨èæ ‡é¢˜: {clip['recommended_title'] or 'ï¼ˆæŸ¥çœ‹æ ‡é¢˜æç¤ºè¯ï¼‰'}")
            print(f"       ğŸ“ ç²¾å½©åŸå› : {clip['reason'][:50]}..." if len(clip['reason']) > 50 else f"       ğŸ“ ç²¾å½©åŸå› : {clip['reason']}")
            print(f"       ğŸ·ï¸  æ ‡ç­¾: {', '.join(clip['tags'][:3])}")
            print(f"       ğŸ“‚ è¯¦æƒ…: {plan_file}")
        
        print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print(f"   1. æŸ¥çœ‹åˆ‡ç‰‡æ–¹æ¡ˆæ–‡ä»¶: {plan_file}")
        print(f"   2. ä½¿ç”¨æ ‡é¢˜æç¤ºè¯æ–‡ä»¶ç”Ÿæˆæœ€ç»ˆæ ‡é¢˜")
        print(f"   3. è¿è¡Œ clip_and_burn.py æ‰§è¡Œå®é™…å‰ªè¾‘")
        
        return final_plan

    def _parse_time_to_seconds(self, time_str: str) -> float:
        """è§£ææ—¶é—´å­—ç¬¦ä¸²ä¸ºç§’"""
        if isinstance(time_str, (int, float)):
            return float(time_str)
        
        parts = time_str.split(":")
        try:
            if len(parts) == 3:
                return int(parts[0]) * 3600 + int(parts[1]) * 60 + float(parts[2])
            elif len(parts) == 2:
                return int(parts[0]) * 60 + float(parts[1])
            return float(parts[0])
        except:
            return 0

    def _format_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ–ç§’ä¸ºæ—¶é—´å­—ç¬¦ä¸²"""
        if seconds is None:
            return "00:00"
        mins = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{mins:02d}:{secs:02d}"

    def _parse_text_result(self, text: str) -> List[Dict]:
        """ä»æ–‡æœ¬è§£æ AI åˆ†æç»“æœï¼ˆfallbackï¼‰"""
        highlights = []
        
        # å°è¯•æå–æ—¶é—´ä¿¡æ¯
        time_patterns = [
            r"(\d{1,2}:\d{2})[-~â€“](\d{1,2}:\d{2})",
            r"(\d{1,2}:\d{2}:\d{2})[-~â€“](\d{1,2}:\d{2}:\d{2})",
        ]
        
        for pattern in time_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                highlights.append({
                    "start_time": match[0],
                    "end_time": match[1],
                    "title": "AIè¯†åˆ«çš„ç²¾å½©ç‰‡æ®µ",
                    "reason": text[:100]
                })
        
        return highlights[:5]


def main():
    parser = argparse.ArgumentParser(description="AI-powered æ™ºèƒ½åˆ‡ç‰‡")
    parser.add_argument("--subtitle", "-s", help="å­—å¹•æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--ai-result", "-a", help="AI åˆ†æç»“æœ JSON æ–‡ä»¶")
    parser.add_argument("--ai-json", help="AI åˆ†æç»“æœ JSON å­—ç¬¦ä¸²")
    parser.add_argument("--streamer", default="Unknown", help="ä¸»æ’­åç§°")
    parser.add_argument("--template", "-t", help="ä¸»æ’­æ¨¡æ¿æ–‡ä»¶")
    parser.add_argument("--output", "-o", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--clips", "-c", type=int, default=5, help="ç”Ÿæˆåˆ‡ç‰‡æ•°é‡")
    parser.add_argument("--platform", "-p", default="bilibili", help="ç›®æ ‡å¹³å°")
    
    args = parser.parse_args()
    
    # åˆ›å»ºåˆ‡ç‰‡å™¨
    clipper = SmartClipperAI(
        streamer_name=args.streamer,
        template_path=args.template
    )
    
    if args.subtitle:
        if args.ai_result or args.ai_json:
            # ç»§ç»­æµç¨‹
            result = clipper.continue_pipeline(
                subtitle_path=args.subtitle,
                ai_result_path=args.ai_result,
                ai_result_json=args.ai_json,
                output_dir=args.output,
                num_highlights=args.clips,
                platform=args.platform
            )
        else:
            # å¼€å§‹æµç¨‹
            result = clipper.run_full_pipeline(
                subtitle_path=args.subtitle,
                output_dir=args.output,
                num_highlights=args.clips,
                platform=args.platform
            )
    else:
        parser.print_help()
        print("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print("   1. å¼€å§‹å®Œæ•´æµç¨‹:")
        print("      python smart_clipper_ai.py --subtitle video.srt --streamer ä¸»æ’­å")
        print("\n   2. ç»§ç»­æµç¨‹ï¼ˆAI åˆ†æåï¼‰:")
        print("      python smart_clipper_ai.py --subtitle video.srt --ai-result ai_output.json")
        print("\n   3. ä¸€é”®å®Œæˆï¼ˆå·²æœ‰ AI åˆ†æç»“æœï¼‰:")
        print("      python smart_clipper_ai.py --subtitle video.srt --ai-result ai_output.json --output ./")
    
    if "error" in result:
        print(f"\nâŒ é”™è¯¯: {result['error']}")


if __name__ == "__main__":
    main()
