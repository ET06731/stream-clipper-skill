#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI-powered å­—å¹•åˆ†ææ¨¡å—
å€ŸåŠ© AI è¯­ä¹‰ç†è§£èƒ½åŠ›è¿›è¡Œæ·±åº¦å­—å¹•åˆ†æ
"""

import re
import json
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime


@dataclass
class SubtitleEntry:
    """å­—å¹•æ¡ç›®"""
    start: float
    end: float
    text: str
    index: int


@dataclass
class AIDisplaySegment:
    """AIåˆ†æçš„è¯­ä¹‰æ®µè½"""
    start: float
    end: float
    text_preview: str  # å‰100å­—ç¬¦é¢„è§ˆ
    full_text: str    # å®Œæ•´æ–‡æœ¬ï¼ˆAIåˆ†ææ—¶ä½¿ç”¨ï¼‰
    ai_analysis: Optional[Dict] = None  # AIåˆ†æç»“æœ


@dataclass
class HighlightMoment:
    """ç²¾å½©ç‰‡æ®µ"""
    start: float
    end: float
    reason: str
    score: float
    title: str
    description: str
    keywords: List[str]
    quote: Optional[str] = None


class SubtitleAnalyzerAI:
    """
    AI-powered å­—å¹•åˆ†æå™¨
    
    è®¾è®¡åŸåˆ™ï¼š
    1. å‡†å¤‡ AI-friendly çš„ç»“æ„åŒ–æ•°æ®
    2. ç”Ÿæˆè¯¦ç»†çš„åˆ†ææç¤ºè¯
    3. æ”¯æŒ Claude/GPT ç­‰ LLM è¿›è¡Œæ·±åº¦è¯­ä¹‰åˆ†æ
    4. ä¿ç•™ fallback è§„åˆ™åˆ†æï¼ˆæ—  AI æ—¶ä½¿ç”¨ï¼‰
    """

    # ç”¨äºæ—¶é—´æ ¼å¼è½¬æ¢çš„å·¥å…·å‡½æ•°
    @staticmethod
    def time_to_seconds(time_str: str) -> float:
        """å°†æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºç§’"""
        time_str = time_str.strip().replace(",", ".")
        parts = time_str.split(":")
        if len(parts) == 3:
            return int(parts[0]) * 3600 + int(parts[1]) * 60 + float(parts[2])
        elif len(parts) == 2:
            return int(parts[0]) * 60 + float(parts[1])
        return float(parts[0])

    @staticmethod
    def seconds_to_time(seconds: float, include_hours: bool = True) -> str:
        """å°†ç§’è½¬æ¢ä¸ºæ—¶é—´å­—ç¬¦ä¸²"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        if include_hours or hours > 0:
            return f"{hours:02d}:{minutes:02d}:{secs:02d}"
        return f"{minutes:02d}:{secs:02d}"

    def __init__(self, streamer_name: str = "Unknown", streamer_template: Dict = None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            streamer_name: ä¸»æ’­åç§°
            streamer_template: ä¸»æ’­æ¨¡æ¿ï¼ˆåŒ…å«é£æ ¼ã€æ¢—ç­‰ä¿¡æ¯ï¼‰
        """
        self.streamer_name = streamer_name
        self.streamer_template = streamer_template or {}
        self.memes = self.streamer_template.get("memes", [])
        self.focus_on = self.streamer_template.get("clip_config", {}).get("focus_on", [])

    def parse_srt(self, srt_path: str) -> List[SubtitleEntry]:
        """è§£æ SRT å­—å¹•æ–‡ä»¶"""
        entries = []
        
        if not Path(srt_path).exists():
            raise FileNotFoundError(f"å­—å¹•æ–‡ä»¶ä¸å­˜åœ¨: {srt_path}")
        
        with open(srt_path, "r", encoding="utf-8") as f:
            content = f.read()
        
        # åˆ†å‰²å­—å¹•å—
        blocks = re.split(r"\n\n+", content.strip())
        
        for block in blocks:
            lines = block.strip().split("\n")
            if len(lines) < 3:
                continue
            
            try:
                index = int(lines[0])
            except ValueError:
                continue
            
            # è§£ææ—¶é—´æˆ³
            time_line = lines[1]
            time_match = re.match(
                r"(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[,\.]\d{3})",
                time_line
            )
            if not time_match:
                continue
            
            start = self.time_to_seconds(time_match.group(1))
            end = self.time_to_seconds(time_match.group(2))
            text = " ".join(lines[2:])
            
            entries.append(SubtitleEntry(start=start, end=end, text=text, index=index))
        
        return entries

    def prepare_ai_analysis_data(self, subtitles: List[SubtitleEntry]) -> Dict:
        """
        å‡†å¤‡ AI åˆ†ææ‰€éœ€çš„æ•°æ®
        
        Returns:
            ç»“æ„åŒ–çš„æ•°æ®ï¼ŒåŒ…å«ï¼š
            - å­—å¹•æ¦‚è§ˆ
            - åˆ†æ®µæ–‡æœ¬ï¼ˆç”¨äºè¯é¢˜åˆ†æï¼‰
            - AI æç¤ºè¯
        """
        if not subtitles:
            return {"error": "æ— å­—å¹•æ•°æ®"}
        
        # 1. ç»Ÿè®¡ä¿¡æ¯
        total_duration = subtitles[-1].end - subtitles[0].start
        total_entries = len(subtitles)
        
        # 2. åˆå¹¶ä¸ºè¿ç»­æ–‡æœ¬ï¼ˆç”¨äºé•¿æ–‡æœ¬åˆ†æï¼‰
        full_text = " ".join([s.text for s in subtitles])
        
        # 3. åˆ†æ®µï¼ˆæ¯æ®µçº¦500å­—ï¼Œç”¨äºè¯é¢˜åˆ†æï¼‰
        segments = self._create_text_segments(subtitles, max_chars=500)
        
        # 4. é«˜å¯†åº¦æ—¶æ®µæ£€æµ‹ï¼ˆåŸºäºæ—¶é—´é—´éš”ï¼‰
        dense_moments = self._detect_dense_moments(subtitles)
        
        # 5. ç”Ÿæˆ AI æç¤ºè¯
        ai_prompt = self._generate_analysis_prompt(
            full_text=full_text[:3000],  # é™åˆ¶é•¿åº¦
            segments=segments,
            dense_moments=dense_moments,
            memes=self.memes,
            focus_on=self.focus_on
        )
        
        return {
            "metadata": {
                "streamer_name": self.streamer_name,
                "total_duration_seconds": total_duration,
                "total_duration_display": self.seconds_to_time(total_duration),
                "total_subtitles": total_entries,
                "analyzed_at": datetime.now().isoformat(),
                "template_focus": self.focus_on
            },
            "segments": segments,
            "dense_moments": dense_moments,
            "ai_prompt": ai_prompt,
            "full_text_preview": full_text[:1000] + ("..." if len(full_text) > 1000 else "")
        }

    def _create_text_segments(self, subtitles: List[SubtitleEntry], max_chars: int = 500) -> List[Dict]:
        """åˆ›å»ºæ–‡æœ¬åˆ†æ®µç”¨äºåˆ†æ"""
        segments = []
        current_segment = []
        current_chars = 0
        segment_start = 0
        
        for i, sub in enumerate(subtitles):
            sub_len = len(sub.text)
            
            if current_chars + sub_len > max_chars and current_segment:
                # ä¿å­˜å½“å‰æ®µ
                segment_text = " ".join([s.text for s in current_segment])
                segments.append({
                    "start_time": self.seconds_to_time(segment_start),
                    "end_time": self.seconds_to_time(current_segment[-1].end),
                    "start_seconds": segment_start,
                    "end_seconds": current_segment[-1].end,
                    "text": segment_text,
                    "text_preview": segment_text[:100] + ("..." if len(segment_text) > 100 else ""),
                    "subtitle_count": len(current_segment)
                })
                
                # å¼€å§‹æ–°æ®µ
                current_segment = [sub]
                current_chars = sub_len
                segment_start = sub.start
            else:
                current_segment.append(sub)
                current_chars += sub_len
        
        # ä¿å­˜æœ€åä¸€æ®µ
        if current_segment:
            segment_text = " ".join([s.text for s in current_segment])
            segments.append({
                "start_time": self.seconds_to_time(segment_start),
                "end_time": self.seconds_to_time(current_segment[-1].end),
                "start_seconds": segment_start,
                "end_seconds": current_segment[-1].end,
                "text": segment_text,
                "text_preview": segment_text[:100] + ("..." if len(segment_text) > 100 else ""),
                "subtitle_count": len(current_segment)
            })
        
        return segments

    def _detect_dense_moments(self, subtitles: List[SubtitleEntry], window_seconds: float = 60.0) -> List[Dict]:
        """æ£€æµ‹å­—å¹•å¯†é›†æ—¶æ®µ"""
        if not subtitles:
            return []
        
        dense_moments = []
        total_duration = subtitles[-1].end
        
        # è®¡ç®—æ¯ä¸ªæ—¶é—´çª—å£çš„å­—å¹•æ•°é‡
        window_count = int(total_duration / window_seconds) + 1
        
        for i in range(window_count):
            window_start = i * window_seconds
            window_end = window_start + window_seconds
            
            count = sum(1 for s in subtitles if window_start <= s.start < window_end)
            
            if count >= 5:  # è‡³å°‘æœ‰5æ¡å­—å¹•
                dense_moments.append({
                    "time_range": f"{self.seconds_to_time(window_start)}-{self.seconds_to_time(window_end)}",
                    "start_seconds": window_start,
                    "end_seconds": window_end,
                    "subtitle_count": count,
                    "density": count / window_seconds  # æ¡/ç§’
                })
        
        # æŒ‰å¯†åº¦æ’åº
        dense_moments.sort(key=lambda x: x["density"], reverse=True)
        
        return dense_moments[:10]  # è¿”å›å‰10ä¸ªå¯†é›†æ—¶æ®µ

    def _generate_analysis_prompt(
        self,
        full_text: str,
        segments: List[Dict],
        dense_moments: List[Dict],
        memes: List[str],
        focus_on: List[str]
    ) -> str:
        """ç”Ÿæˆ AI åˆ†ææç¤ºè¯"""
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç›´æ’­åˆ‡ç‰‡åˆ†æå¸ˆã€‚è¯·åˆ†æä»¥ä¸‹ç›´æ’­å­—å¹•æ•°æ®ï¼Œè¯†åˆ«ç²¾å½©ç‰‡æ®µã€‚

## ä¸»æ’­ä¿¡æ¯
- ä¸»æ’­åç§°: {self.streamer_name}
- é‡ç‚¹å…³æ³¨: {', '.join(focus_on) if focus_on else 'é«˜èƒ½æ—¶åˆ»ã€ç²¾å½©å¯¹è¯'}
- ä¸»æ’­æ¢—/å£å¤´ç¦…: {', '.join(memes) if memes else 'æ— ç‰¹å®šæ¢—'}

## å­—å¹•æ•°æ®æ¦‚è§ˆ
- å­—å¹•æ®µæ•°: {len(segments)}
- å¯†é›†æ—¶æ®µæ•°: {len(dense_moments)}

## å¯†é›†æ—¶æ®µï¼ˆé«˜äº’åŠ¨åŒºåŸŸï¼‰
"""
        
        for moment in dense_moments[:5]:
            prompt += f"- {moment['time_range']}: {moment['subtitle_count']}æ¡å­—å¹•\n"
        
        prompt += f"""
## å­—å¹•å†…å®¹ï¼ˆæŒ‰æ—¶é—´åˆ†æ®µï¼‰

"""
        for i, seg in enumerate(segments[:10]):  # å–å‰10æ®µ
            prompt += f"ã€{seg['start_time']} - {seg['end_time']}ã€‘\n{seg['text'][:200]}\n\n"
        
        prompt += """
## åˆ†æä»»åŠ¡

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡º JSON åˆ†æç»“æœï¼š

```json
{
  "highlights": [
    {
      "start_seconds": 123.0,
      "end_seconds": 189.0,
      "duration_seconds": 66,
      "title": "ç²¾å½©ç‰‡æ®µæ ‡é¢˜ï¼ˆ10-20å­—ï¼‰",
      "reason": "ä¸ºä»€ä¹ˆè¿™æ˜¯ç²¾å½©ç‰‡æ®µï¼ˆ50å­—ä»¥å†…ï¼‰",
      "score": 0.95,
      "keywords": ["å…³é”®è¯1", "å…³é”®è¯2", "å…³é”®è¯3"],
      "quote": "ç‰‡æ®µä¸­æœ€å€¼å¾—å¼•ç”¨çš„ä¸€å¥è¯",
      "description": "ç‰‡æ®µå†…å®¹çš„ç®€è¦æè¿°ï¼ˆ100å­—ä»¥å†…ï¼‰"
    }
  ],
  "topics": [
    {
      "start_seconds": 0.0,
      "end_seconds": 300.0,
      "topic": "è¯é¢˜åç§°",
      "description": "è¯é¢˜å†…å®¹æè¿°"
    }
  ],
  "memes_detected": ["æ£€æµ‹åˆ°çš„æ¢—1", "æ£€æµ‹åˆ°çš„æ¢—2"],
  "overall_mood": "æ•´ä½“æ°›å›´æè¿°ï¼ˆå¦‚ï¼šæ¬¢ä¹ã€æŠ€æœ¯è®¨è®ºã€æƒ…æ„Ÿäº¤æµç­‰ï¼‰"
}
```

## è¦æ±‚
1. è¯†åˆ« 3-5 ä¸ªæœ€ç²¾å½©çš„ç‰‡æ®µ
2. è¯„åˆ†åŸºäºï¼šäº’åŠ¨å¯†åº¦ã€å†…å®¹ä»·å€¼ã€æƒ…ç»ªå¼ºåº¦ã€æ¢—çš„å‡ºç°
3. æ¯ä¸ªç‰‡æ®µæ—¶é•¿å»ºè®® 60-180 ç§’
4. æ ‡é¢˜è¦å¸å¼•äººï¼Œèƒ½å‡†ç¡®åæ˜ å†…å®¹
5. ç¡®ä¿è¾“å‡ºæœ‰æ•ˆçš„ JSON æ ¼å¼

è¯·å¼€å§‹åˆ†æï¼š"""
        
        return prompt

    def generate_title_prompt(
        self,
        highlight: Dict,
        streamer_template: Dict = None
    ) -> str:
        """ç”Ÿæˆæ ‡é¢˜ç”Ÿæˆçš„ AI æç¤ºè¯"""
        
        template = streamer_template or self.streamer_template
        upload_template = template.get("upload_template", {})
        title_template = upload_template.get("title_template", "[{streamer}]{topic}")
        memes = template.get("memes", [])
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¤¾äº¤åª’ä½“æ ‡é¢˜ä¸“å®¶ã€‚è¯·ä¸ºä»¥ä¸‹ç›´æ’­ç‰‡æ®µç”Ÿæˆå¸å¼•äººçš„æ ‡é¢˜ã€‚

## ä¸»æ’­ä¿¡æ¯
- ä¸»æ’­: {self.streamer_name}
- é£æ ¼: {template.get('style', {}).get('tone', 'å¹½é»˜é£è¶£')}
- æ¢—: {', '.join(memes[:5]) if memes else 'æ— '}

## ç‰‡æ®µä¿¡æ¯
- å¼€å§‹æ—¶é—´: {self.seconds_to_time(highlight['start_seconds'])}
- ç»“æŸæ—¶é—´: {self.seconds_to_time(highlight['end_seconds'])}
- æ—¶é•¿: {highlight.get('duration_seconds', 'æœªçŸ¥')}ç§’
- æ¨èæ ‡é¢˜: {highlight.get('title', 'æ— ')}
- ç²¾å½©åŸå› : {highlight.get('reason', 'æ— ')}
- é‡‘å¥å¼•ç”¨: {highlight.get('quote', 'æ— ')}
- å…³é”®è¯: {', '.join(highlight.get('keywords', []))}
- æè¿°: {highlight.get('description', 'æ— ')}

## æ ‡é¢˜æ¨¡æ¿
å‚è€ƒæ ¼å¼: {title_template}

## è¾“å‡ºè¦æ±‚
ç”Ÿæˆ 3 ä¸ªæ ‡é¢˜é€‰é¡¹ï¼š

1. **æ‚¬å¿µå‹**: åˆ¶é€ å¥½å¥‡ï¼Œå¸å¼•ç‚¹å‡»
2. **å¼•ç”¨å‹**: ç›´æ¥å¼•ç”¨é‡‘å¥æˆ–å¯¹è¯
3. **è¯é¢˜å‹**: çªå‡ºè¯é¢˜/äº‹ä»¶

æ¯ä¸ªæ ‡é¢˜è¦æ±‚ï¼š
- é•¿åº¦: 15-30 å­—
- åŒ…å«ä¸»æ’­å
- å¸å¼•äººä½†ä¸æ ‡é¢˜å…š
- é€‚åˆ Bilibili å¹³å°

## è¾“å‡ºæ ¼å¼
```json
{{
  "titles": [
    {{
      "type": "æ‚¬å¿µå‹",
      "title": "æ ‡é¢˜å†…å®¹",
      "reason": "ä¸ºä»€ä¹ˆè¿™ä¸ªæ ‡é¢˜æœ‰æ•ˆ"
    }}
  ],
  "recommended": "æœ€ä½³æ ‡é¢˜",
  "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2", "æ ‡ç­¾3", "æ ‡ç­¾4", "æ ‡ç­¾5"]
}
```

è¯·ç”Ÿæˆæ ‡é¢˜ï¼š"""
        
        return prompt

    def analyze_with_ai(self, subtitle_path: str) -> Dict:
        """
        ä½¿ç”¨ AI åˆ†æå­—å¹•ï¼ˆä¸»å…¥å£ï¼‰
        
        æ­¤æ–¹æ³•ä¼šï¼š
        1. è§£æå­—å¹•æ–‡ä»¶
        2. å‡†å¤‡åˆ†ææ•°æ®
        3. ç”Ÿæˆ AI æç¤ºè¯
        4. è¾“å‡ºä¾› AI å¤„ç†çš„ç»“æ„åŒ–æ•°æ®
        
        Returns:
            {
                'metadata': {...},
                'ai_prompt': '...',  # ç”¨äº AI å¤„ç†çš„æç¤ºè¯
                'structured_data': {...},  # å¤‡ç”¨è§„åˆ™åˆ†æç»“æœ
                'output_file': 'åˆ†æç»“æœä¿å­˜è·¯å¾„'
            }
        """
        print(f"\nğŸ¤– AIå­—å¹•åˆ†ææ¨¡å—å¯åŠ¨")
        print(f"   ä¸»æ’­: {self.streamer_name}")
        print(f"   æ–‡ä»¶: {Path(subtitle_path).name}")
        
        # 1. è§£æå­—å¹•
        subtitles = self.parse_srt(subtitle_path)
        print(f"   å­—å¹•æ¡ç›®: {len(subtitles)}")
        
        if not subtitles:
            return {"error": "æ— æ³•è§£æå­—å¹•æ–‡ä»¶"}
        
        # 2. å‡†å¤‡ AI åˆ†ææ•°æ®
        analysis_data = self.prepare_ai_analysis_data(subtitles)
        
        # 3. è¾“å‡ºåˆ†æ
        print(f"\nğŸ“Š åˆ†ææ•°æ®å‡†å¤‡å®Œæˆ:")
        print(f"   - æ€»æ—¶é•¿: {analysis_data['metadata']['total_duration_display']}")
        print(f"   - è¯­ä¹‰åˆ†æ®µ: {len(analysis_data['segments'])}")
        print(f"   - å¯†é›†æ—¶æ®µ: {len(analysis_data['dense_moments'])}")
        
        # 4. ä¿å­˜åˆ†ææ•°æ®
        output_path = Path(subtitle_path).with_suffix(".ai_analysis.json")
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump({
                "metadata": analysis_data["metadata"],
                "ai_prompt": analysis_data["ai_prompt"],
                "segments": analysis_data["segments"],
                "dense_moments": analysis_data["dense_moments"]
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… åˆ†ææ•°æ®å·²ä¿å­˜: {output_path}")
        print(f"\n{'='*60}")
        print("ğŸ“ AI æç¤ºè¯ï¼ˆå¤åˆ¶ç»™ AI åˆ†æï¼‰:")
        print(f"{'='*60}\n")
        print(analysis_data["ai_prompt"])
        print(f"\n{'='*60}")
        print("ğŸ’¡ ä½¿ç”¨æ–¹æ³•: å°†ä¸Šè¿°æç¤ºè¯å‘é€ç»™ AIï¼Œå³å¯è·å¾—ç²¾å½©ç‰‡æ®µåˆ†æç»“æœ")
        print("   AI è¿”å› JSON ç»“æœåï¼Œå¯ç”¨ parse_ai_result() æ–¹æ³•è§£æ")
        
        return {
            "metadata": analysis_data["metadata"],
            "ai_prompt": analysis_data["ai_prompt"],
            "segments": analysis_data["segments"],
            "dense_moments": analysis_data["dense_moments"],
            "output_file": str(output_path)
        }

    def parse_ai_result(self, ai_output: str, output_path: str = None) -> Dict:
        """
        è§£æ AI è¿”å›çš„åˆ†æç»“æœ
        
        Args:
            ai_output: AI è¿”å›çš„æ–‡æœ¬ï¼ˆé€šå¸¸æ˜¯ JSON æ ¼å¼ï¼‰
            output_path: å¯é€‰ï¼Œä¿å­˜è§£æç»“æœ
        
        Returns:
            è§£æåçš„ Dict
        """
        # å°è¯•æå– JSON
        json_match = re.search(r'```json\s*(.+?)\s*```', ai_output, re.DOTALL)
        if json_match:
            try:
                result = json.loads(json_match.group(1))
            except json.JSONDecodeError:
                result = {"raw_output": ai_output}
        else:
            # ç›´æ¥å°è¯•è§£æ
            try:
                result = json.loads(ai_output)
            except json.JSONDecodeError:
                result = {"raw_output": ai_output}
        
        # æ ¼å¼åŒ–æ—¶é—´
        if "highlights" in result:
            for hl in result["highlights"]:
                hl["start_time"] = self.seconds_to_time(hl["start_seconds"])
                hl["end_time"] = self.seconds_to_time(hl["end_seconds"])
        
        if "topics" in result:
            for topic in result["topics"]:
                topic["time_range"] = f"{self.seconds_to_time(topic['start_seconds'])}-{self.seconds_to_time(topic['end_seconds'])}"
        
        # ä¿å­˜ç»“æœ
        if output_path:
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"âœ… AI åˆ†æç»“æœå·²ä¿å­˜: {output_path}")
        
        return result

    def generate_titles_for_highlight(
        self,
        highlight: Dict,
        platform: str = "bilibili"
    ) -> Dict:
        """
        ä¸ºç²¾å½©ç‰‡æ®µç”Ÿæˆæ ‡é¢˜ï¼ˆä½¿ç”¨ AIï¼‰
        
        Args:
            highlight: ç²¾å½©ç‰‡æ®µä¿¡æ¯
            platform: ç›®æ ‡å¹³å°
        
        Returns:
            æ ‡é¢˜ç”Ÿæˆç»“æœ
        """
        prompt = self.generate_title_prompt(highlight, self.streamer_template)
        
        # å°è¯•è§£æ AI è¿”å›çš„ JSON
        # ï¼ˆå®é™…ä½¿ç”¨æ—¶ï¼Œprompt å‘é€ç»™ AIï¼Œè¿”å›ç»“æœç”¨ parse_ai_result è§£æï¼‰
        
        return {
            "input_highlight": highlight,
            "ai_prompt": prompt,
            "streamer": self.streamer_name,
            "platform": platform
        }


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="AI-powered å­—å¹•åˆ†æ")
    parser.add_argument("subtitle", help="å­—å¹•æ–‡ä»¶è·¯å¾„(.srt/.vtt)")
    parser.add_argument("--streamer", "-s", default="Unknown", help="ä¸»æ’­åç§°")
    parser.add_argument("--template", "-t", help="ä¸»æ’­æ¨¡æ¿ YAML æ–‡ä»¶")
    parser.add_argument("--output", "-o", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    # åŠ è½½æ¨¡æ¿ï¼ˆå¦‚æœæœ‰ï¼‰
    streamer_template = None
    if args.template:
        import yaml
        with open(args.template, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f)
            streamer_template = data.get(args.streamer.lower(), data.get("streamers", {}).get(args.streamer.lower()))
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = SubtitleAnalyzerAI(
        streamer_name=args.streamer,
        streamer_template=streamer_template
    )
    
    # æ‰§è¡Œåˆ†æ
    result = analyzer.analyze_with_ai(args.subtitle)
    
    if "error" in result:
        print(f"âŒ é”™è¯¯: {result['error']}")
        return
    
    # ä¿å­˜è¾“å‡º
    output_path = args.output or result.get("output_file")
    if output_path:
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"âœ… ç»“æœå·²ä¿å­˜: {output_path}")


if __name__ == "__main__":
    main()
